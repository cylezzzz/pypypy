
# ğŸ¨ AndioMediaStudio

Ein universelles **lokales KI-Medienstudio** fÃ¼r Desktop & Heimnetzwerk.  
Es kombiniert **Bild- und Video-Generierung**, **Bearbeitung**, **Posenerkennung**, **Lip-Sync**, **Outfit-Editing** und mehr â€” alles mit lokalen Modellen und Agenten (z. B. [Ollama](https://ollama.ai)).

---

## ğŸš€ Features

- **Text â†’ Bild** (Txt2Img)
- **Bild â†’ Bild** (Img2Img)
- **Inpainting / Remover / Outfit-Change**  
- **Automatische Maskierung (SAM / MediaPipe)**
- **Posenerkennung & Pose-Transfer (ControlNet-OpenPose)**
- **Text â†’ Video & Bild â†’ Video** (Stable Video Diffusion, AnimateDiff)
- **Lip-Sync & Talking-Head** (Wav2Lip, SadTalker, vorbereitete Hooks)
- **Galerie & Player** (Web & Desktop)
- **Katalog / Store** â€“ Ãœbersicht aller lokal vorhandenen Modelle
- **Keine Filter** â€“ volle kreative Kontrolle, privat nutzbar

---

## ğŸ“‚ Projektstruktur

```plaintext
AndioMediaStudio/
â”œâ”€ server/              # FastAPI-Backend & Pipelines
â”œâ”€ web/                 # Web-OberflÃ¤che (HTML/CSS/JS)
â”œâ”€ desktop/electron/    # Electron-Wrapper fÃ¼r Desktop-App
â”œâ”€ outputs/             # generierte Ergebnisse (Bilder/Videos)
â”œâ”€ workspace/           # Uploads / Zwischendateien
â””â”€ models/              # Lokale Modelle
```

### Modelle-Verzeichnis

```plaintext
models/
â”œâ”€ image/
â”‚  â”œâ”€ demo-sd15/
â”‚  â”œâ”€ Realistic_Vision_V6.0_B1/
â”‚  â”œâ”€ Realistic_Vision_V6.0_B1_noVAE/
â”‚  â”œâ”€ stable-diffusion-xl-base-1.0/
â”‚  â”œâ”€ stable-diffusion-xl-refiner-1.0/
â”‚  â”œâ”€ tiny-sd/
â”‚  â”œâ”€ sd15.safetensors
â”‚  â”œâ”€ scheduler/
â”‚  â”œâ”€ text_encoder_2/
â”‚  â”œâ”€ tokenizer/
â”‚  â”œâ”€ tokenizer_2/
â”‚  â””â”€ unet/
â”‚
â”œâ”€ llm/
â”‚  â””â”€ ollama.ai
â”‚
â””â”€ video/
   â”œâ”€ animatediff/
   â”œâ”€ AnimateDiff_Motion_Module_V3/
   â”œâ”€ Stable_Video_Diffusion_img2vid_/
   â”œâ”€ stable-video-diffusion-img2vid/
   â”œâ”€ stable-video-diffusion-img2vid-xt/
   â”œâ”€ wav2lip/        # hier wav2lip_gan.pth ablegen
   â””â”€ sadtalker/      # SadTalker Pretrained-Files
```

â„¹ï¸ Details findest du in [`models/README_models.txt`](models/README_models.txt).

---

## ğŸ”§ Installation

### Voraussetzungen
- **Python 3.10+**
- **GPU mit CUDA** empfohlen (NVIDIA)
- **Node.js 20+** (nur wenn du Electron-Desktop nutzen willst)
- **Git** (fÃ¼r Repo-Management)
- Optional: **Ollama** (LLM-Agent)

### Setup
```bash
# AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt

# Backend starten
python start.py
```

Danach im Browser:  
ğŸ‘‰ [http://localhost:3000](http://localhost:3000)  
(oder von anderen GerÃ¤ten im Heimnetz `http://<PC-IP>:3000`)

---

## ğŸ’» Desktop-App (Electron)

```bash
cd desktop/electron
npm install
npm start
```

---

## ğŸ“¡ API-Endpoints

- **POST `/api/jobs`** â€“ Startet eine Aufgabe  
  Beispiel (Txt2Img):
  ```json
  {
    "task": "txt2img",
    "prompt": "ultrarealistisches Portrait, 85mm, volumetrisches Licht",
    "quality": "ULTRA",
    "model_preference": "Realistic_Vision_V6.0_B1"
  }
  ```

- **POST `/api/upload`** â€“ Datei hochladen (landet in `workspace/`)  
- **GET `/api/models`** â€“ Listet verfÃ¼gbare Modelle  
- **GET `/api/outputs`** â€“ Zeigt generierte Bilder/Videos  
- **POST `/api/auto_mask`** â€“ Automatische Maske erzeugen (SAM / MediaPipe)

---

## âš™ï¸ Besondere Features

- **Auto-Maske**  
  Nutzt SAM-Checkpoint (`models/image/sam/*.pth`) oder fallback MediaPipe Selfie Segmentation.
- **ControlNet-Pose**  
  Erwartet ein OpenPose-ControlNet-Modell (`models/image/controlnet/â€¦`).
- **Lip-Sync (Wav2Lip)**  
  `wav2lip_gan.pth` in `models/video/wav2lip/` einfÃ¼gen.  
  Den Hook in `server/pipelines/lipsync_wav2lip.py` ggf. an dein Repo anpassen.
- **Talking-Head (SadTalker)**  
  SadTalker Pretrained-Modelle in `models/video/sadtalker/`.

---

## âš ï¸ Hinweise

- **Dieses Projekt ist rein fÃ¼r private, kreative Nutzung gedacht.**
- Es gibt **keine Blockierungen oder Filter** â€“ du hast volle Freiheit.
- GroÃŸe Modelle werden **nicht ins GitHub-Repo hochgeladen** (siehe `.gitignore`).

---

## ğŸ“œ Lizenz

Privates Projekt â€“ Nutzung auf eigene Verantwortung.
